"""
GitHubçƒ­é—¨é¡¹ç›®å·¥å…·
è·å–GitHubä¸Šçƒ­é—¨çš„AIç›¸å…³é¡¹ç›®å’Œä»“åº“
"""

import requests
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
from github import Github, GithubException

from src.tools.base_tool import BaseNewsTool, NewsItem
from src.utils.logger import get_logger
from src.utils.datetime_utils import normalize_datetime, safe_datetime_subtract, get_utc_now, days_since


class GitHubTrendingTool(BaseNewsTool):
    """GitHubçƒ­é—¨é¡¹ç›®å·¥å…·"""
    
    name = "github_trending"
    description = "è·å–GitHubä¸Šçƒ­é—¨çš„AIç›¸å…³é¡¹ç›®"
    inputs = {
        "topics": {
            "type": "array",
            "description": "GitHubä¸»é¢˜åˆ—è¡¨ï¼Œå¦‚['artificial-intelligence', 'machine-learning']"
        },
        "max_repos": {
            "type": "integer",
            "description": "æœ€å¤§ä»“åº“æ•°é‡",
            "nullable": True
        },
        "min_stars": {
            "type": "integer",
            "description": "æœ€å°æ˜Ÿæ ‡æ•°é‡",
            "nullable": True
        }
    }
    output_type = "string"
    
    def __init__(self, github_token: Optional[str] = None, **kwargs):
        super().__init__(**kwargs)
        self.github_token = github_token
        self.github = Github(github_token) if github_token else Github()
        self.rate_limit_delay = 3.0  # GitHub APIæœ‰ä¸¥æ ¼çš„é€Ÿç‡é™åˆ¶
        self.max_retries = 3  # æœ€å¤§é‡è¯•æ¬¡æ•°
    
    def forward(self, topics: List[str], max_repos: int = 10, min_stars: int = 100) -> str:
        """
        è·å–GitHubçƒ­é—¨é¡¹ç›®
        
        Args:
            topics: GitHubä¸»é¢˜åˆ—è¡¨
            max_repos: æœ€å¤§ä»“åº“æ•°é‡
            min_stars: æœ€å°æ˜Ÿæ ‡æ•°é‡
            
        Returns:
            str: é¡¹ç›®ç»“æœçš„JSONå­—ç¬¦ä¸²
        """
        try:
            repos = self.fetch_with_cache(
                topics=topics,
                max_repos=max_repos,
                min_stars=min_stars
            )
            
            # è½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼è¿”å›
            results = []
            for repo in repos:
                results.append({
                    'title': repo.title,
                    'content': repo.content[:700] + '...' if len(repo.content) > 700 else repo.content,
                    'url': repo.url,
                    'source': repo.source,
                    'published_date': repo.published_date.isoformat(),
                    'tags': repo.tags,
                    'score': repo.score
                })
            
            import json
            return json.dumps(results, ensure_ascii=False, indent=2)
        
        except Exception as e:
            self.logger.error(f"GitHubçƒ­é—¨é¡¹ç›®è·å–å¤±è´¥: {e}")
            return f"è·å–å¤±è´¥: {str(e)}"
    
    def _fetch_news(self, topics: List[str], max_repos: int = 10, min_stars: int = 100) -> List[NewsItem]:
        """
        è·å–GitHubçƒ­é—¨é¡¹ç›®
        
        Args:
            topics: GitHubä¸»é¢˜åˆ—è¡¨
            max_repos: æœ€å¤§ä»“åº“æ•°é‡
            min_stars: æœ€å°æ˜Ÿæ ‡æ•°é‡
            
        Returns:
            List[NewsItem]: é¡¹ç›®åˆ—è¡¨
        """
        all_repos = []
        
        try:
            # è·å–çƒ­é—¨ä»“åº“
            trending_repos = self._get_trending_repos(topics, max_repos, min_stars)
            all_repos.extend(trending_repos)
            
            # è·å–æœ€è¿‘æ›´æ–°çš„ä»“åº“
            recent_repos = self._get_recent_repos(topics, max_repos // 2, min_stars)
            all_repos.extend(recent_repos)
            
        except Exception as e:
            self.logger.error(f"è·å–GitHubæ•°æ®å¤±è´¥: {e}")
        
        # å»é‡å’Œæ’åº
        unique_repos = self.deduplicate(all_repos, threshold=0.9)
        unique_repos.sort(key=lambda x: x.score, reverse=True)
        
        return unique_repos[:max_repos]
    
    def _get_trending_repos(self, topics: List[str], max_repos: int, min_stars: int) -> List[NewsItem]:
        """
        è·å–çƒ­é—¨ä»“åº“
        
        Args:
            topics: ä¸»é¢˜åˆ—è¡¨
            max_repos: æœ€å¤§ä»“åº“æ•°é‡
            min_stars: æœ€å°æ˜Ÿæ ‡æ•°é‡
            
        Returns:
            List[NewsItem]: ä»“åº“åˆ—è¡¨
        """
        repos = []
        
        for topic in topics:
            self.logger.info(f"æœç´¢GitHubä¸»é¢˜: {topic}")
            
            try:
                # æ„å»ºæœç´¢æŸ¥è¯¢
                query = f"topic:{topic} stars:>={min_stars}"
                
                # æœç´¢ä»“åº“ï¼ˆæŒ‰æ˜Ÿæ ‡æ•°æ’åºï¼‰
                search_result = self.github.search_repositories(
                    query=query,
                    sort="stars",
                    order="desc"
                )
                
                # å¤„ç†æœç´¢ç»“æœ
                count = 0
                for repo in search_result:
                    if count >= max_repos // len(topics):
                        break
                    
                    try:
                        repo_info = self._get_repo_info(repo)
                        if repo_info:
                            news_item = NewsItem(
                                title=f"çƒ­é—¨é¡¹ç›®: {repo.full_name}",
                                content=self._format_repo_content(repo_info),
                                url=repo.html_url,
                                source=f"github_{topic}",
                                published_date=repo.created_at,
                                tags=self._extract_repo_tags(repo_info, topic)
                            )
                            
                            # è®¡ç®—çƒ­åº¦åˆ†æ•°
                            news_item.score = self._calculate_repo_score(repo_info)
                            repos.append(news_item)
                            count += 1
                    
                    except Exception as e:
                        self.logger.warning(f"å¤„ç†ä»“åº“å¤±è´¥ {repo.full_name}: {e}")
                        continue
                
                self._rate_limit()
                
            except GithubException as e:
                self.logger.error(f"æœç´¢GitHubä¸»é¢˜ '{topic}' å¤±è´¥: {e}")
                continue
            except Exception as e:
                self.logger.error(f"å¤„ç†GitHubä¸»é¢˜ '{topic}' å¤±è´¥: {e}")
                continue
        
        return repos
    
    def _get_recent_repos(self, topics: List[str], max_repos: int, min_stars: int) -> List[NewsItem]:
        """
        è·å–æœ€è¿‘æ›´æ–°çš„ä»“åº“
        
        Args:
            topics: ä¸»é¢˜åˆ—è¡¨
            max_repos: æœ€å¤§ä»“åº“æ•°é‡
            min_stars: æœ€å°æ˜Ÿæ ‡æ•°é‡
            
        Returns:
            List[NewsItem]: ä»“åº“åˆ—è¡¨
        """
        repos = []
        
        # æœç´¢æœ€è¿‘30å¤©æ›´æ–°çš„ä»“åº“
        recent_date = get_utc_now() - timedelta(days=30)
        date_str = recent_date.strftime("%Y-%m-%d")
        
        for topic in topics:
            try:
                query = f"topic:{topic} stars:>={min_stars} pushed:>{date_str}"
                
                search_result = self.github.search_repositories(
                    query=query,
                    sort="updated",
                    order="desc"
                )
                
                count = 0
                for repo in search_result:
                    if count >= max_repos // len(topics):
                        break
                    
                    try:
                        repo_info = self._get_repo_info(repo)
                        if repo_info:
                            news_item = NewsItem(
                                title=f"æœ€è¿‘æ›´æ–°: {repo.full_name}",
                                content=self._format_repo_content(repo_info),
                                url=repo.html_url,
                                source=f"github_recent_{topic}",
                                published_date=repo.updated_at,
                                tags=self._extract_repo_tags(repo_info, topic) + ['recent-update']
                            )
                            
                            news_item.score = self._calculate_repo_score(repo_info) * 0.8  # ç¨å¾®é™ä½åˆ†æ•°
                            repos.append(news_item)
                            count += 1
                    
                    except Exception as e:
                        self.logger.warning(f"å¤„ç†æœ€è¿‘ä»“åº“å¤±è´¥ {repo.full_name}: {e}")
                        continue
                
                self._rate_limit()
                
            except Exception as e:
                self.logger.error(f"æœç´¢æœ€è¿‘æ›´æ–°ä»“åº“å¤±è´¥ '{topic}': {e}")
                continue
        
        return repos
    
    def _get_repo_info(self, repo) -> Optional[Dict[str, Any]]:
        """
        è·å–ä»“åº“è¯¦ç»†ä¿¡æ¯
        
        Args:
            repo: GitHubä»“åº“å¯¹è±¡
            
        Returns:
            Optional[Dict[str, Any]]: ä»“åº“ä¿¡æ¯
        """
        try:
            return {
                'full_name': repo.full_name,
                'name': repo.name,
                'owner': repo.owner.login,
                'description': repo.description or '',
                'stars': repo.stargazers_count,
                'forks': repo.forks_count,
                'watchers': repo.watchers_count,
                'language': repo.language,
                'topics': repo.get_topics(),
                'created_at': repo.created_at,
                'updated_at': repo.updated_at,
                'pushed_at': repo.pushed_at,
                'size': repo.size,
                'open_issues': repo.open_issues_count,
                'license': repo.license.name if repo.license else None,
                'html_url': repo.html_url,
                'clone_url': repo.clone_url,
                'homepage': repo.homepage
            }
        
        except Exception as e:
            self.logger.warning(f"è·å–ä»“åº“ä¿¡æ¯å¤±è´¥: {e}")
            return None
    
    def _format_repo_content(self, repo_info: Dict[str, Any]) -> str:
        """
        æ ¼å¼åŒ–ä»“åº“å†…å®¹
        
        Args:
            repo_info: ä»“åº“ä¿¡æ¯
            
        Returns:
            str: æ ¼å¼åŒ–åçš„å†…å®¹
        """
        content_parts = []
        
        content_parts.append(f"ä»“åº“: {repo_info['full_name']}")
        
        if repo_info.get('description'):
            content_parts.append(f"æè¿°: {repo_info['description']}")
        
        content_parts.append(f"â­ æ˜Ÿæ ‡: {repo_info['stars']:,}")
        content_parts.append(f"ğŸ´ åˆ†å‰: {repo_info['forks']:,}")
        content_parts.append(f"ğŸ‘€ å…³æ³¨: {repo_info['watchers']:,}")
        
        if repo_info.get('language'):
            content_parts.append(f"ä¸»è¦è¯­è¨€: {repo_info['language']}")
        
        if repo_info.get('topics'):
            topics = ", ".join(repo_info['topics'][:8])
            content_parts.append(f"ä¸»é¢˜: {topics}")
        
        if repo_info.get('license'):
            content_parts.append(f"è®¸å¯è¯: {repo_info['license']}")
        
        content_parts.append(f"åˆ›å»ºæ—¶é—´: {repo_info['created_at'].strftime('%Y-%m-%d')}")
        content_parts.append(f"æœ€åæ›´æ–°: {repo_info['updated_at'].strftime('%Y-%m-%d')}")
        
        if repo_info.get('homepage'):
            content_parts.append(f"ä¸»é¡µ: {repo_info['homepage']}")
        
        return "\n".join(content_parts)
    
    def _extract_repo_tags(self, repo_info: Dict[str, Any], topic: str) -> List[str]:
        """
        æå–ä»“åº“æ ‡ç­¾
        
        Args:
            repo_info: ä»“åº“ä¿¡æ¯
            topic: ä¸»é¢˜
            
        Returns:
            List[str]: æ ‡ç­¾åˆ—è¡¨
        """
        tags = ['github', 'repository', topic]
        
        if repo_info.get('language'):
            tags.append(repo_info['language'].lower())
        
        if repo_info.get('topics'):
            tags.extend(repo_info['topics'][:5])
        
        # æ ¹æ®æ˜Ÿæ ‡æ•°æ·»åŠ çƒ­åº¦æ ‡ç­¾
        stars = repo_info.get('stars', 0)
        if stars > 10000:
            tags.append('super-popular')
        elif stars > 5000:
            tags.append('very-popular')
        elif stars > 1000:
            tags.append('popular')
        
        return list(set(tags))
    
    def _calculate_repo_score(self, repo_info: Dict[str, Any]) -> float:
        """
        è®¡ç®—ä»“åº“çƒ­åº¦åˆ†æ•°
        
        Args:
            repo_info: ä»“åº“ä¿¡æ¯
            
        Returns:
            float: çƒ­åº¦åˆ†æ•°
        """
        score = 0.0
        
        # æ˜Ÿæ ‡æ•°æƒé‡
        stars = repo_info.get('stars', 0)
        score += min(stars / 1000, 10.0) * 0.4
        
        # åˆ†å‰æ•°æƒé‡
        forks = repo_info.get('forks', 0)
        score += min(forks / 100, 5.0) * 0.2
        
        # æœ€è¿‘æ´»è·ƒåº¦æƒé‡
        if repo_info.get('updated_at'):
            try:
                days_since_update = days_since(repo_info['updated_at'])
                if days_since_update is not None:
                    if days_since_update < 7:
                        score += 2.0
                    elif days_since_update < 30:
                        score += 1.0
                    elif days_since_update < 90:
                        score += 0.5
                else:
                    score += 0.5
            except Exception as e:
                self.logger.warning(f"è®¡ç®—æ´»è·ƒåº¦æ—¶å‡ºé”™: {e}")
                score += 0.5
        
        # é—®é¢˜æ•°é‡ï¼ˆåå‘æƒé‡ï¼‰
        open_issues = repo_info.get('open_issues', 0)
        if open_issues < 10:
            score += 0.5
        elif open_issues > 100:
            score -= 0.5
        
        # è¯­è¨€æƒé‡
        popular_languages = ['Python', 'JavaScript', 'TypeScript', 'Go', 'Rust', 'C++']
        if repo_info.get('language') in popular_languages:
            score += 0.3
        
        return max(score, 0.0)
    
    def get_trending_topics(self) -> List[str]:
        """
        è·å–çƒ­é—¨AIç›¸å…³ä¸»é¢˜
        
        Returns:
            List[str]: ä¸»é¢˜åˆ—è¡¨
        """
        return [
            'artificial-intelligence',
            'machine-learning',
            'deep-learning',
            'neural-networks',
            'computer-vision',
            'natural-language-processing',
            'reinforcement-learning',
            'generative-ai',
            'large-language-models',
            'transformers',
            'pytorch',
            'tensorflow',
            'huggingface',
            'openai',
            'chatgpt'
        ]
